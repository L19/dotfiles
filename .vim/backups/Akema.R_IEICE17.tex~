%% template for IEICE Transactions
%% v2.1 [2015/10/31]
\documentclass[paper]{ieice}
%\documentclass[invited]{ieice}
%\documentclass[position]{ieice}
%\documentclass[survey]{ieice}
%\documentclass[invitedsurvey]{ieice}
%\documentclass[review]{ieice}
%\documentclass[tutorial]{ieice}
%\documentclass[letter]{ieice}
%\documentclass[brief]{ieice}
%\usepackage[dvips]{graphicx}
%\usepackage[pdftex]{graphicx,xcolor}
\usepackage[dvipdfmx]{graphicx,xcolor}
\usepackage[fleqn]{amsmath}
%\usepackage{newtxtext}
%\usepackage[varg]{newtxmath}
\usepackage{bm,amsfonts,amsthm}
\usepackage[linesnumbered,ruled,vlined]{algorithm2e}
\usepackage{enumitem}
\usepackage{relsize}

\setcounter{page}{1}

%\breakauthorline{}% breaks lines after the n-th author

\field{A}
%\SpecialIssue{}
%\SpecialSection{}
%\theme{}
\title{An exact simultaneous diagonalization with eigenvectors of a special large matrix}
%\title[title for header]{title}
%\titlenote{}
\authorlist{%
  \authorentry[akmea@sp.ce.titech.ac.jp]{Riku Akema}{n}{TiTech}\MembershipNumber{}
  \authorentry[myamagi@sp.ce.titech.ac.jp]{Masao Yamagishi}{m}{TiTech}\MembershipNumber{}
  \authorentry[isao@sp.ce.titech.ac.jp]{Isao Yamada}{f}{TiTech}\MembershipNumber{}
  % \authorentry[e-mail address]{name}{membership}{affiliate label}\MembershipNumber{}
  % \authorentry[e-mail address]{name}{membership}{affiliate label}[present affiliate label]\MembershipNumber{}
}
\affiliate[TiTech]{
  The author are with the
  \EICdepartment{Department of Information and Communications Engineering}
  \EICorganization{Tokyo Institute of Technology}
  \EICaddress{2-12-1-S3-60 Ookayama, Meguro-ku, Tokyo 152-8550, Japan}
}
%\paffiliate[present affiliate label]{Presently, the author is with the }

\received{2017}{1}{1}
\revised{2017}{1}{1}

%% <local definitions here>
\newtheorem{problem}{Problem}
\newtheorem{theo}{Theorem}
\newtheorem{lemma}{Lemma}
\newtheorem{fact}{Fact}
\newtheorem{defin}{Definition}
\newtheorem{assum}{Assumption}
\newtheorem{corol}{Corollary}
\makeatletter
\DeclareRobustCommand{\rvdots}{%
  \vbox{
    \baselineskip4\p@\lineskiplimit\z@
    \hbox{.}\hbox{.}\hbox{.}
  }}
\makeatother
%% </local definitions here>

\begin{document}
\maketitle
\begin{summary}

\end{summary}
\begin{keywords}

\end{keywords}

\section{Introduction}
The Simultaneous Diagonalization(SD), also called joint eigenvalue decomposition, of real matrices has been attracted great attention and has diverse signal processing applications: blind source separation\cite{}, multi-dimensional harmonic retrieval\cite{}, and canonical polyadic decomposition\cite{}. The SD problem of our interest is
\begin{problem}[The SD problem of real matrices]
  \label{prob:SD}
  Denote $GL(N,\mathbb{R}) \subset \mathbb{R}^{N \times N}$ be the set of all nonsingular matrices. Let $\{R_{\tau}\}_{\tau=1}^{T}\subset \mathbb{R}^{N\times N}$ be a family of (possibly unsymmetric) matrices. Find $M_{\star} \in GL(N,\mathbb{R})$ such that $M_{\star}^{-1}R_{\tau}M_{\star}$ is diagonal for any $\tau=1,2,\ldots ,T$.
\end{problem}
{\bf Notation:} Let $\mathbb{R}$ and $GL(N,\mathbb{R})$ denote the set of all real numbers and the set of all nonsingular matrices which are in $\mathbb{R}^{N\times N}$, respectively. 
Denote the Kronecker product by $\otimes$.
Denote columnwise vectorization of a matrix by ${\rm vec}(\cdot)\colon \mathbb{R}^{N \times N} \to \mathbb{R}^{N^2}$ and its inversion by ${\rm vec}^{-1}(\cdot)$.
For a matrix, $\| \cdot \|_{F}$ is the Frobenius norm, $\| \cdot \|_\ast$ is the nuclear norm (i.e., sum of the singular values), and $\|\cdot\|_{2}$ is 2-norm (i.e., the largest singular value).
For a square matrix $R \in \mathbb{R}^{N \times N}$, an eigenvalue of $R$ is called \emph{simple} if its algebraic multiplicity is one, on the other hand, called \emph{repeated} otherwise.
A square matrix $R \in \mathbb{R}^{N \times N}$ is called {\it diagonalizable} if there exists $M\in GL(N,\mathbb{R})$ such that $M^{-1} R M$ is diagonal. 
Two square matrices $A, B \in \mathbb{R}^{N \times N}$ are said to {\it commute} if $AB = BA$.


\section{Preliminaries}
\label{sec:preli}
% We shall list some known results on properties on solutions of Problem \ref{prob:SD}.
\subsection{Properties on solutions of Problem \ref{prob:SD}}
\begin{defin}
  A family $\mathcal{F} \subset \mathbb{R}^{N \times N}$ of matrices is a nonempty finite or infinite set of matrices; a {\rm commuting family} is a family of matrices in which every pair of matrices commutes. $\mathcal{F}$ is said to be {\rm simultaneous diagonalizable} if there is a single nonsingular $M \in GL(N,\mathbb{R})$ such that $M^{-1} R M$ is diagonal for every $R \in \mathcal{F}$.
\end{defin}
\begin{fact}[Existence of solutions of Problem \ref{prob:SD}]
  \label{fa:existence}
  Suppose that $\{R_{\tau}\}_{\tau=1}^{T}\subset \mathbb{R}^{N\times N}$ in Problem \ref{prob:SD} is a family of diagonalizable matrices. Then the following conditions are equivalent:
  \begin{itemize}
    \item[(a)] Problem \ref{prob:SD} has a solution;
    \item[(b)] $\{R_{\tau}\}_{\tau=1}^{T}$ is a simultaneous diagonalizable family;
    \item[(c)] $\{R_{\tau}\}_{\tau=1}^{T}$ is a commuting family.
  \end{itemize}  
\end{fact}
Note that Fact \ref{fa:existence} is an immediate consequence by ~\cite[Theorem 1.3.21]{horn2012matrix}.

Obviously, if $M$ is a solution of Problem \ref{prob:SD}, then $M \Pi D$ is also another solution for any permutation $\Pi \in \mathbb{R}^{N \times N}$ and any nonsingular diagonal $D \in \mathbb{R}^{N\times N}$. 
Hence any solution $M$ of Problem \ref{prob:SD} can be unique only up to a permutation and a scaling of its columns. 
\begin{fact}[{Essential uniqueness of the SD \cite[Theorem 6.1]{de2004computation}}]
  \label{fa:esseUniq}
  Suppose that $M \in GL(N,\mathbb{R})$ is a solution of Problem \ref{prob:SD}. 
  Then, the SD
  \begin{align}
    & (\forall \tau \in \{1,2,\ldots, T\}) \nonumber \\
    & \quad M^{-1} R_{\tau} M  =: \Sigma_{\tau} \label{eq: JEDL} = \operatorname{diag}(\sigma_1^{(\tau)}, \sigma_2^{(\tau)}, \ldots  \sigma_N^{(\tau)})
  \end{align}
  is unique up to a permutation and a scaling of its column if and only if
  \begin{align}
    \label{eq:esseUniq}
    & (\forall i \neq j,\ i, j \in \{1, 2, \ldots , N\}) \nonumber \\
    & \quad \left[
      \begin{array}{c}
        \sigma^{(1)}_i \\
        \sigma^{(2)}_i \\
        \vdots \\
        \sigma^{(T)}_i
      \end{array}
    \right] =: \hat{\bm{s}}_i \neq \hat{\bm{s}}_j \in \mathbb{R}^{T}.
  \end{align}
\end{fact}
\vspace{1cm}

\subsection{DODO method}
DODO method is suggested by the classical proof that a commuting family of diagonalizable matrices can be simultaneously diagonalized\cite[Theorem 1.3.21]{horn2012matrix}. Let $\{R_\tau\}_{\tau=1}^T\subset\mathbb{R}^{N^2\times N^2}$ in Problem \ref{prob:SD} be a simultaneous diagonalizable family. DODO approach (i) uses a solver of eigenvalue problems to diagonalize a matrix $R_{\tau'}\ (\tau'\in\{1,2,\ldots ,T\})$; (ii) groups together any repeated eigenvalues of $R_{\tau'}$, i.e.,
\begin{align}
  \Sigma_{\tau'}&=M_1^{-1}R_{\tau'}M_1\nonumber\\
                &=\left[
    \begin{array}{cccc}
      \sigma_1I_{n_1}&&&O\\
                     &\sigma_2I_{n_2}&&\\
                     &&\ddots&\\
      O&&&\sigma_dI_{n_d}
    \end{array}
  \right],\label{eq:partition}
\end{align}
where $M_1\in GL(N,\mathbb{R})$ is a matrix whose column vectors are the eigenvectors of $R_{\tau'}$, $\sigma_1,\ldots ,\sigma_d\in\mathbb{R}$ are the distinct eigenvalues of $R_{\tau'}$, $n_1,\ldots ,n_d\in\{1,2,\ldots ,N\}$ are their respective multiplicities, and $I_{n_i}\in GL(n_i,\mathbb{R})$ is an identity matrix; and then (iii) performs the similarly transformation by the similarly matrix $M_1$ to the others. Since $\Sigma_{\tau'}$ and the other matrix $B^{(\tau'')}\ (\tau''\in\{1,2,\ldots ,T\}\backslash\{\tau'\})$ in $\{M_1^{-1}R_\tau M_1\}_{\tau=1}^{T}$ commute,
\begin{align}
  &(\forall i,j\in\{1,2,\ldots ,d\})\ \sigma_iB^{(\tau'')}_{i,j}=\sigma_jB^{(\tau'')}_{i,j}\label{eq:partitionIden1}\\
  \Leftrightarrow\ &(\forall i,j\in\{1,2,\ldots ,d\})\ (\sigma_i-\sigma_j)B^{(\tau'')}_{i,j}=0,\label{eq:partitionIten2}
\end{align}
where $B^{(\tau'')}_{i,j}$ is a block matrix in $B^{(\tau'')}$ partitioned conformally with $\Sigma_{\tau'}$. The identities in \eqref{eq:partitionIden1} and \eqref{eq:partitionIten2} are satisfied if and only if $B^{(\tau'')}_{i,j}=O$ whenever $i\neq j$. Therefore $B^{(\tau'')}$ is block diagonal. (iv) By applying the procedures (i)-(iii) to a commuting family $\mathcal{B}_i:=\{B_{i,i}^{(\tau)}\in\mathbb{R}^{n_i\times n_i}\mid\tau\in\{1,2,\ldots ,T\}\backslash\{\tau'\},i\in\{1,2,\ldots, d\},n_i\ge2\}$,
\begin{align*}
  M_2:=\left[
    \begin{array}{ccccc}
      I_{n_1}&&&&O\\
             &\ddots&&&\\
             &&M_{i,i}&&\\
             &&&\ddots&\\
             O&&&&I_{n_d}
    \end{array}
  \right]\in GL(N,\mathbb{R}),
\end{align*}
where $M_{i,i}\in GL(n_i,\mathbb{R})$ is the similarly matrix in (iii) for $\mathcal{B}_i$. Repeating these procedures (i)-(iv) until the all matrices in $\{R_\tau\}_{\tau=1}^T$ are diagonal, we can obtain a solution of Problem \ref{prob:SD}:
\begin{align*}
  M=M_1M_2\cdot\cdots\cdot M_K\in GL(N,\mathbb{R}),
\end{align*}
where $K$ is number of repeating (see Algorithm \ref{algo:DODO}).

\begin{algorithm}[t]
  \SetAlgoLined
  \SetKwProg{Fn}{Function}{}{end}
  \SetKwFunction{DODO}{DODO}

  \KwIn{A simultaneous diagonalizable family $\{R_\tau\}_{\tau=1}^T\subset\mathbb{R}^{N\times N}$ in Problem \ref{prob:SD}}
  \KwOut{The diagonal family $\{\Sigma_\tau\}_{\tau=1}^T\subset\mathbb{R}^{N\times N}$ and a solution $M\in GL(N,\mathbb{R})$ of Problem \ref{prob:SD}}
  \BlankLine
  \Fn{\DODO{$\mathcal{R}$}}{
    Let $n$ be the size of the matrices in $\mathcal{R}$\;
    \eIf{All matrices in $\mathcal{R}$ are diagonal}{
      \KwRet $\left(\mathcal{R}, I_n\right)$\;
      }{
      Choose $R\in\mathcal{R}$ which is not diagonal\;
    }
    Diagonalize $R$, then group together any repeated eigenvalues of $R$, i.e.,
    \begin{align*}
      \Sigma&:=M'^{-1}RM'\\
            &=\left[
        \begin{array}{cccc}
          \sigma_1I_{n_1}&&&O\\
                         &\sigma_2I_{n_2}&&\\
                         &&\ddots&\\
          O&&&\sigma_dI_{n_d}
        \end{array}
      \right]
    \end{align*}
    \;
    \ $\mathcal{B}:=\left\{B\in\mathbb{R}^{n\times n}\mid\forall R'\in\mathcal{R},B=M'^{-1}R'M'\right\}$\;
    $\tilde{M}:=M'$\;
    \For{$i=1$ \KwTo $d$}{
      \If{$n_i>1$}{
        Let $\mathcal{B}_{i}\subset\mathbb{R}^{n_i\times n_i}$ be a set of the $i$-th diagonal blocks of matrices in $\mathcal{B}$ partitioned conformally with $\Sigma$\;
        $\left(\mathcal{D}_i, \tilde{M}_i\right)=$ \DODO{$\mathcal{B}_i$}\;
        Update $\mathcal{B}_i$ and $\tilde{M}$ as
        \begin{align*}
          \mathcal{B}_i&=\mathcal{D}_i\\
          \tilde{M}&=\tilde{M}\left[
            \begin{array}{ccccc}
              I_{n_1}&&&&O\\
                     &\ddots&&&\\
                     &&\tilde{M}_{i}&&\\
                     &&&\ddots&\\
                     O&&&&I_{n_d}
            \end{array}
          \right]
        \end{align*}
        \;
      }
    }
    \KwRet $(\mathcal{B},\tilde{M})$\;
  }
  $\left(\{\Sigma_\tau\}_{\tau=1}^T, M\right)=$ \DODO{$\{R_\tau\}_{\tau=1}^T$}
  \caption{DODO method}
  \label{algo:DODO}
\end{algorithm}


\section{A special large matrix $Q$}
\label{seq: proposed}
We present a relationship between Problem \ref{prob:SD} and eigenvectors of a special large matrix under the assumption that a solution exists.
\begin{theo}[Necessary condition of all solutions of Problem \ref{prob:SD}]
  \label{theo: JDviaED}
  Suppose that $M\in\mathbb{R}^{N\times N}$ is a solution of Problem \ref{prob:SD}.
  For $\{R_{\tau}\}_{\tau=1}^{T}\subset \mathbb{R}^{N\times N}$ in Problem \ref{prob:SD}, define matrices
  \begin{align}	    
    \hat{R}_{k} & :=\left[
      \begin{array}{cccc}
        r^{(1)}_{k,1} & r^{(1)}_{k,2} & \cdots & r^{(1)}_{k,N}\\
        r^{(2)}_{k,1} & r^{(2)}_{k,2} & \cdots & r^{(2)}_{k,N}\\
                      & \vdots & & \\
        r^{(\tau)}_{k,1} & r^{(\tau)}_{k,2} & \cdots & r^{(\tau)}_{k,N}\\
                         & \vdots & & \\
        r^{(T)}_{k,1} & r^{(T)}_{k,2} & \cdots & r^{(T)}_{k,N}
      \end{array}
    \right]\in \mathbb{R}^{T\times N}  \nonumber \\
    \label{eq:Rhat}
    & \hspace{3.5cm} (k = 1, 2, \ldots , N), \\
    \label{eq:Q}
    Q & :=\left[
      \begin{array}{c}
        {\rm vec}(\hat{R}_{1}^\top\hat{R}_{1})^\top\\
        {\rm vec}(\hat{R}_{2}^\top\hat{R}_{1})^\top\\
        \vdots\\
        {\rm vec}(\hat{R}_{N}^\top\hat{R}_{1})^\top\\
        {\rm vec}(\hat{R}_{1}^\top\hat{R}_{2})^\top\\
        {\rm vec}(\hat{R}_{2}^\top\hat{R}_{2})^\top\\
        \vdots\\
        {\rm vec}(\hat{R}_{N}^\top\hat{R}_{N})^\top
      \end{array}
    \right]\in\mathbb{R}^{N^2\times N^2},
  \end{align}
  with $(k, l)$ entries $r^{(\tau)}_{k, l}\ (l = 1,2,\ldots N)$ of $R_\tau$. Then, $Q$ has eigen-pairs such that 
  \begin{align}
    \label{eq: eigenpair}
    (\lambda_{i,j}, \bm{v}_{i,j})&:=\left(\sum_{\tau=1}^T\sigma_i^{(\tau)}\sigma_j^{(\tau)}, {\rm vec}(\bm{m}_{i}\bm{m}_{j}^{\top})\right)\in\mathbb{R}\times\mathbb{R}^{N^2}\\
    & \hspace{2.5cm}(i,j=1,2,\ldots ,N), \nonumber
  \end{align}
  where $\bm{m}_{i}\in\mathbb{R}^{N}$ is the $i$-th column vector of $M$ and $\sigma_1^{(\tau)},\sigma_2^{(\tau)},\ldots , \sigma_N^{(\tau)}$ are the eigenvalues of $R_\tau$ defined as in \eqref{eq: JEDL}.
\end{theo}

\begin{proof}
  Denote the $k$-th row vector of $R_\tau$ by $\bm{r}^{(\tau)}_k \in \mathbb{R}^{1 \times N}$, similarly, the $k$-th row vector of $M$ by $\bm{m}_{k, :} \in \mathbb{R}^{1 \times N}$, and introduce a vector $\bm{\sigma}_\tau \in \mathbb{R}^{1 \times N}$ satisfying that $\operatorname{diag}(\bm{\sigma}_\tau) = \Sigma_\tau$. Describing the $j$-th row of $R_{\tau}$ yields
  \begin{align}
    & (M\ {\rm is\ a\ solution\ of\ Problem\ \ref{prob:SD}})\nonumber\\
    \Leftrightarrow \  & (\forall \tau \in \{1, 2, \ldots , T\})\ R_\tau = M \Sigma_\tau M^{-1} \nonumber \\
    \Leftrightarrow \  & (\forall k \in\{1, 2, \ldots ,N\})(\forall \tau\in\{1,2, \ldots ,T\}) \nonumber \\
                       & \quad \bm{r}^{(\tau)}_k = \bm{m}_{k, :} \operatorname{diag}(\bm{\sigma}_{\tau}) M^{-1} \nonumber \\
    \label{eq:Rkthrow}
    & \hspace{1cm} = \bm{\sigma}_\tau \operatorname{diag}(\bm{m}_{k, :}) M^{-1}.
  \end{align}
  Let $\hat{S} \in \mathbb{R}^{T \times N}$ be a matrix whose the $\tau$-th row vector is $\bm{\sigma}_\tau$. Constructing $\hat{R}_j$ defined as in \eqref{eq:Rhat}, we have
  \begin{align}
    \eqref{eq:Rkthrow} \Leftrightarrow \ & (\forall k \in \{1, 2, \ldots , N\})\nonumber \\
                                         & \quad \hat{R}_k = \left[ \begin{array}{c}
    \bm{r}^{(1)}_k \\
    \bm{r}^{(2)}_k \\
    \vdots \\
    \bm{r}^{(T)}_k
  \end{array}
  \right] = \left[
  \begin{array}{c}
    \bm{\sigma}_1 \\
    \bm{\sigma}_2 \\
    \vdots \\
    \bm{\sigma}_T
  \end{array}
\right] \operatorname{diag}(\bm{m}_{k, :}) M^{-1} \nonumber \\
& \hspace{2.7cm} = \hat{S} \operatorname{diag}(\bm{m}_{k, :})M^{-1} \nonumber \\
\label{eq:RhatM}
\Leftrightarrow\ & (\forall k \in \{1, 2, \ldots , N\})\ \hat{R}_k M = \hat{S} \operatorname{diag}(\bm{m}_{k, :})
  \end{align}
  Describing the $i$-th column vector of both sides of \eqref{eq:RhatM} yields
  \begin{align}
    \label{eq:Rhatm}
    \eqref{eq:RhatM} \Leftrightarrow (\forall i,k\in\{1, 2, \ldots ,N\})\ \hat{R}_{k}\bm{m}_{i}=\hat{\bm{s}}_{i}m_{k,i},
  \end{align}
  where $\bm{m}_{i}\in\mathbb{R}^{N}$ is the $i$-th column vector of $M$, $m_{j,i}\in\mathbb{R}$ is the $(j,i)$ element of $M$, and $\hat{\bm{s}}_{i}\in\mathbb{R}^{T}$ is the $i$-th column vector of $\hat{S}$. 

  Now, using the last equation of \eqref{eq:Rhatm} with $\hat{R}_k\bm{m}_i$ and $\hat{R}_l\bm{m}_j(l=1,2,\ldots ,N)$, we construct the $(k + (l - 1)N)$-th row vector of $Q\in\mathbb{R}^{N^{2}\times N^{2}}$. Considering a inner product of $\hat{R}_k\bm{m}_i$ and $\hat{R}_l\bm{m}_j$, we have
  \begin{align}
    \label{eq:quadForm}
    \eqref{eq:Rhatm} \Rightarrow\  & (\forall i,j,k,l\in\{1,2,\ldots ,N\})\nonumber\\
                                   &\quad\bm{m}_j^{\top}\hat{R}_l^{\top}\hat{R}_k\bm{m}_{i} = m_{l,j}m_{k,i}\hat{\bm{s}}_{j}^\top\hat{\bm{s}}_{i} \nonumber \\
    \Leftrightarrow\ & (\forall i,j,k,l\in\{1,2,\ldots ,N\})\nonumber\\
                     & \quad {\rm tr}\left(\bm{m}_j^{\top}\hat{R}_l^{\top}\hat{R}_k\bm{m}_{i}\right) = m_{l,j}m_{k,i}\hat{\bm{s}}_{j}^\top\hat{\bm{s}}_{i}\nonumber\\
    \Leftrightarrow\ & (\forall i,j,k,l \in \{1,2,\ldots ,N\})\nonumber\\
                     &\quad{\rm tr}\left(\hat{R}_{l}^{\top}\hat{R}_{k}\bm{m}_{i}\bm{m}_{j}^{\top}\right) = m_{l,j}m_{k,i}\hat{\bm{s}}_{j}^\top\hat{\bm{s}}_{i}\nonumber\\
    \Leftrightarrow\ & (\forall i,j,k,l\in\{1,2,\ldots ,N\})\nonumber\\
                     &\quad{\rm vec}(\hat{R}_{k}^{\top}\hat{R}_{l})^\top{\rm vec}(\bm{m}_{i}\bm{m}_{j}^{\top}) = m_{k,i}m_{l,j}\hat{\bm{s}}_{i}^\top\hat{\bm{s}}_{j}.\nonumber\\
  \end{align}
  Constructing $Q$ by using all ${\rm vec}(\hat{R}_{k}^{\top}\hat{R}_{l})^{\top}\in\mathbb{R}^{1\times N^2}$, we have
  \begin{eqnarray}
    \eqref{eq:quadForm} &\Leftrightarrow & (\forall i,j\in\{1,2,\ldots ,N\})\nonumber\\
                        &&\quad Q\ {\rm vec}(\bm{m}_{i}\bm{m}_{j}^{\top}) = \hat{\bm{s}}_{i}^\top\hat{\bm{s}}_{j}{\rm vec}(\bm{m}_{i}\bm{m}_{j}^{\top}). \nonumber
  \end{eqnarray}
  The last equation implies that ${\rm vec}(\bm{m}_{i}\bm{m}_{j}^{\top}) = \bm{v}_{i, j}$ is an eigenvector of $Q$ and its associate eigenvalue is $\hat{\bm{s}}_{i}^\top\hat{\bm{s}}_{j} = \lambda_{i, j}\in\mathbb{R}$.
\end{proof}

Theorem \ref{theo: JDviaED} implies that a solution of Problem \ref{prob:SD} can be constructed from the eigenvectors of $Q$ which contains not only a single matrix in $\{R_\tau\}_{\tau=1}^T$ but also all the given matrices. In addition, we present some special properties of the eigen-pairs of $Q$.

\begin{corol}
  \label{cor:eigPairProp}
  Let $\hat{\bm{s}}_i\in\mathbb{R}^{T}\ (i=1,2,\ldots ,N)$ be a vector defined as in \eqref{eq:esseUniq}. Then, the eigen-pairs $(\lambda_{i,j}, \bm{v}_{i,j}) \in \mathbb{R} \times \mathbb{R}^{N}\ (j=1,2,\ldots ,N)$ defined as in \eqref{eq: eigenpair} have the following properties:
  \begin{enumerate}[label=(\alph*)]
    % \item $\{\lambda_{1,1},\lambda_{2,2},\ldots ,\lambda_{N,N}\}$ contains at most $N$ simple eigenvalues;
    \item $\lambda_{i,j} = \hat{\bm{s}}_i^\top\hat{\bm{s}}_j = \lambda_{j,i}$ for any $i,j=1,2,\ldots ,N$; \label{enum:eigValEq}
    \item ${\rm rank}({\rm vec}^{-1}(\bm{v}_{i,j}))={\rm rank}(\bm{m}_i\bm{m}_j^\top)=1$ for any $i,j=1,2,\ldots ,N$; \label{enum:rank1}
    \item ${\rm vec}^{-1}(\bm{v}_{i,j})=\bm{m}_i\bm{m}_j^\top$ is unsymmetric for any $i,j=1,2,\ldots ,N\colon i \not = j$; \label{enum:unsym}
    \item ${\rm vec}^{-1}(\bm{v}_{i,i})=\bm{m}_i\bm{m}_i^\top$ is symmetric for any $i=1,2,\ldots ,N$; \label{enum:sym}
    \item any column vector of ${\rm vec}^{-1}(\bm{v}_{i,i})$ is proportional to $\bm{m}_{i}$ for any $i=1,2,\ldots ,N$. \label{enum:colPro}
  \end{enumerate}
\end{corol}

Combining Theorem \ref{theo: JDviaED} and Corollary \ref{cor:eigPairProp}, we present a new algorithm for solving Problem \ref{prob:SD} in Section \ref{sec:proposedAlg}. The following theorem attains a basic idea of our algorithm.

% Corollary \ref{cor:eigPairProp} implies that, from $\bm{v}_{i,i}$, we can obtain the $i$-th column $\bm{m}_i$ of a solution $M$ of Problem \ref{prob:SD} by picking out any column vector of ${\rm vec}^{-1}(\bm{v}_{i,i})$.
% This idea yields our proposed algorithm comprising three procedures: (i) obtain all the eigenvectors $\hat{\bm{v}}_\iota\in\mathbb{R}^{N^2}(\iota=1,2,\ldots ,N^2)$ of $Q$;
% (ii) search eigenvectors $\{\tilde{\bm{v}}_{\iota'}\}_{\iota'=1}^N$ idential to desired ones $\{\bm{v}_{i,i}\}_{i=1}^N$ based on properties \ref{enum:rank1} and \ref{enum:sym};
% (iii) recovering all columns of $M$ from the column vectors of ${\rm vec}^{-1}(\tilde{\bm{v}}_{\iota'})$ by property \ref{enum:colPro}
% (see Algorithm 1 for its detailed steps).
% 
% Depending on the multiplicity of $\lambda_{i,i}\ (i=1,2,\ldots ,N)$ in \eqref{eq: eigenpair}, we can find more than $N$ eigenvectors in Step 2 of Algorithm \ref{algo: proposed}. The following theorem presents that at most $N$ eigenvectors are found in Step 2 if and only if the SD is essentially unique.
% 

\begin{theo}
  \label{theo:simpEigVal}
  Suppose that $M \in GL(N,\mathbb{R})$ is a solution of Problem \ref{prob:SD}. Let $Q\in\mathbb{R}^{N^2\times N^2}$ be a matrix defined as in \eqref{eq:Q}. If $Q$ has $n(\le N)$ simple eigenvalues, then $n$ column vectors of $M$ are obtained from $n$ eigenvectors associated with these eigenvalues.
\end{theo}

\begin{proof}
  Let $\lambda_{i,j}\in\mathbb{R}\ (i,j=1,2,\ldots ,N)$ be an eigenvalue of $Q$ defined as in \eqref{eq: eigenpair}. Since the multiplicity of $\lambda_{i,j},\ (i\neq j)$ is at least two by using Corollary \ref{cor:eigPairProp} \ref{enum:eigValEq}, $n$ simple eigenvalues corresponds to $\lambda_{\iota,\iota}\ (\iota\in\{1,2,\ldots ,N\})$. Therefore, by using Theorem \ref{theo: JDviaED}, an eigenvector $\tilde{\bm{v}}\in\mathbb{R}^{N^2}$ associated with the simple eigenvalue is represented as
  \begin{align*}
    (\exists\iota\in\{1,2,\ldots ,N\})\ \tilde{\bm{v}}\in\operatorname{span}\{\operatorname{vec}(\bm{m}_\iota\bm{m}_\iota^\top)\}
  \end{align*}
  with the $\iota$-th column vector $\bm{m}_\iota$ of $M$. By using Corollary \ref{cor:eigPairProp} \ref{enum:colPro}, a vector proportional to $\bm{m}_\iota$ is obtained from $\tilde{\bm{v}}$.
\end{proof}

Now, 

\begin{lemma}
  \label{lem:eigVecLinInd}
  Let $Q\in\mathbb{R}^{N^2\times N^2}$ be a matrix defined as in \eqref{eq:Q}. Then, the eigenvectors $\{\bm{v}_{i,j}\}_{i,j=1}^{N}\subset\mathbb{R}^{N^2}$ of $Q$ defined as in \eqref{eq: eigenpair} are linearly independent.
\end{lemma}
\begin{proof}
  Suppose that $M:=[\bm{m}_1,\bm{m}_2,\ldots ,\bm{m}_N]\in GL(N,\mathbb{R})$ is a solution of Problem \ref{prob:SD}. Since
  \begin{align*}
    \bm{v}_{i,j}=\operatorname{vec}(\bm{m}_i\bm{m}_j^\top)=\bm{m}_j\otimes\bm{m}_i,
  \end{align*}
  a matrix whose the $i+(j-1)N$-th column vector is $\bm{v}_{i,j}$ is represented as
  \begin{align*}
    \left[\bm{v}_{1,1}, \bm{v}_{2,1}, \ldots ,\bm{v}_{N,1}, \bm{v}_{1,2}, \ldots , \bm{v}_{N,N}\right]=M\otimes M.
  \end{align*}
  Since $M$ is nonsingular matrix, $M\otimes M$ is also nonsingular. Therefore $\{\bm{v}_{i,j}\}_{i,j=1}^{N}$ are linearly independent.
\end{proof}

\begin{theo}
  \label{theo:equiEsseUniq}
  Suppose that $M := [\bm{m}_1,\bm{m}_2,\ldots ,\bm{m}_N] \in GL(N,\mathbb{R})$ is a solution of Problem \ref{prob:SD}. Let $Q\in\mathbb{R}^{N^2\times N^2}$ be a matrix defined as in \eqref{eq:Q} and $\tilde{\bm{v}} \in \mathbb{R}^{N^2}$ be an eigenvector of $Q$. Then, the following conditions are equivalent:
  \begin{enumerate}[label=(\alph*)]
    \item \label{enum:esseUniq} $M$ is essentially unique;
    \item \label{enum:vTilCond1} if $\tilde{\bm{v}}$ satisfies
      \begin{align*}
        \left\{
          \begin{array}{l}
            {\rm vec}^{-1}(\tilde{\bm{v}}) \text{ is symmetric;}\\
            {\rm rank}({\rm vec}^{-1}(\tilde{\bm{v}})) = 1,
          \end{array}
        \right.
      \end{align*}
      then
      \begin{align*}
        (\exists i\in\{1,2,\ldots ,N\})\ \tilde{\bm{v}}\in\operatorname{span}\{\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)\};
      \end{align*}
    \item \label{enum:vTilCond2}
      \begin{align*} 
        &\left\{\tilde{\bm{v}}\in\mathbb{R}^{N^2}\middle|
        \begin{array}{l}
          {\rm vec}^{-1}(\tilde{\bm{v}}) \text{ is symmetric,}\\
          {\rm rank}({\rm vec}^{-1}(\tilde{\bm{v}})) = 1
        \end{array}
      \right\}\\
      &\hspace{3cm}=\bigcup_{i=1}^N\operatorname{span}\{\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)\}.
    \end{align*}
  \end{enumerate}
\end{theo}

\begin{proof}
  (\ref{enum:esseUniq}$\Leftrightarrow$\ref{enum:vTilCond1}) We will prove that the contrapositive is true. Let $\hat{\bm{s}}_i\in\mathbb{R}^{T}\ (i=1,2,\ldots ,N)$ be a vector defined as in \eqref{eq:esseUniq} and $\lambda_{i,j}\in\mathbb{R}\ (j=1,2,\ldots ,N)$ be an eigenvalue of $Q$ defined as in \eqref{eq: eigenpair}. From Fact \ref{fa:esseUniq}, we have
  \begin{align}
    &(\text{The solution } M \text{ is {\it not} essentially unique})\nonumber\\
    \Leftrightarrow\ & (\exists i\neq j,\ i,j\in\{1,2,\ldots ,N\})\ \hat{\bm{s}}_i=\hat{\bm{s}}_j.\label{eq:notEsseUniq}
  \end{align}
  Using Cauchy-Schwarz inequality and Corollary \ref{cor:eigPairProp} \ref{enum:eigValEq}, we have
  \begin{align}
    \eqref{eq:notEsseUniq}&\Leftrightarrow(\exists i\neq j,\ i,j\in\{1,2,\ldots ,N\})\nonumber\\
                          &\hspace{3cm}\|\hat{\bm{s}}_i\|^2_2=\|\hat{\bm{s}}_j\|^2_2=\hat{\bm{s}}_i^\top\hat{\bm{s}}_j\nonumber\\
                          &\Leftrightarrow(\exists i\neq j,\ i,j\in\{1,2,\ldots ,N\})\nonumber\\
                          &\hspace{1.8cm}\lambda_{i,i}=\lambda_{j,j}=\lambda_{i,j}=\lambda_{j,i}=:\tilde{\lambda}.\label{eq:lamijEqual}
  \end{align}
  From Theorem \ref{theo: JDviaED}, since the eigenspace of $Q\in\mathbb{R}^{N^2\times N^2}$ associated with the eigenvalue $\lambda_{i,j}$ is spanned by $\operatorname{vec}(\bm{m}_i\bm{m}_j^\top) = \bm{v}_{i,j}$, its eigenspace associated with the eigenvalue $\tilde{\lambda}$ in \eqref{eq:lamijEqual} is spanned by $\bm{v}_{i,i}, \bm{v}_{j,j}, \bm{v}_{i,j}$, and $\bm{v}_{j,i}$. Hence $Q$ has an eigenvector
  \begin{align}
    \tilde{\bm{v}}:=&\ \alpha_i^2\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)+\alpha_i\alpha_j\operatorname{vec}(\bm{m}_i\bm{m}_j^\top)\nonumber\\
                    &\quad+\alpha_j\alpha_i\operatorname{vec}(\bm{m}_j\bm{m}_i^\top)+\alpha_j^2\operatorname{vec}(\bm{m}_j\bm{m}_j^\top)\nonumber\\
    =&\operatorname{vec}\left([\bm{m}_i\ \bm{m}_j]\left[
    \begin{array}{cc}
      \alpha_i^2&\alpha_i\alpha_j\\
      \alpha_j\alpha_i&\alpha_j^2
    \end{array}
    \right]\left[
    \begin{array}{c}
      \bm{m}_i^\top\\
      \bm{m}_j^\top
    \end{array}
    \right]\right)\nonumber\\
    &=\operatorname{vec}(M\bm{a}\bm{a}^\top M^\top)\in\mathbb{R}^{N^2}\label{eq:vTilde}
  \end{align}
  with
  \begin{align*}
    \bm{a} & :=
    \left[
      \begin{array}{c}
        0 \\
        \rvdots \\
        \alpha_i \\
        0 \\
        \rvdots \\
        \alpha_j \\
        0 \\
        \rvdots \\
        0
      \end{array}
    \right] \hspace{-0.3cm}
    \begin{array}{c}
      \\
      \\
      \leftarrow i \\
      \\
      \\
      \leftarrow j \\
      \\
      \\
      \\
    \end{array}
    \in\mathbb{R}^{N},\quad\alpha_i,\alpha_j\in\mathbb{R}\backslash\{0\}.
  \end{align*}
  The eigenvector $\tilde{\bm{v}}$ satisfies
  \begin{align}
    \operatorname{vec}^{-1}(\tilde{\bm{v}})=M\bm{a}\bm{a}^\top M^\top=(M\bm{a}\bm{a}^\top M^\top)^\top,\label{eq:vTilSym}
  \end{align}
  and, as $M$ is nonsingular matrix,
  \begin{align}
    \operatorname{rank}\left(\operatorname{vec}^{-1}(\tilde{\bm{v}})\right)&=\operatorname{rank}(M\bm{a}\bm{a}^\top M^\top)\nonumber\\
                                                                           &=\operatorname{rank}(\bm{a}\bm{a}^\top)=1.\label{eq:vTilRank1}
  \end{align}
  These implies
  \begin{align}
    \eqref{eq:lamijEqual}&\Rightarrow\left[\left.
      \begin{array}{l}
        {\rm vec}^{-1}(\tilde{\bm{v}}) \text{ is symmetric,}\\
        {\rm rank}({\rm vec}^{-1}(\tilde{\bm{v}})) = 1,
      \end{array}
    \right\}\right.\nonumber\\
    &\hspace{1cm}\Rightarrow\left.
    \begin{array}{l}
      (\exists i\neq j,\  i,j\in\{1,2,\ldots ,N\})\\
      \quad\tilde{\bm{v}}\in\operatorname{span}\{\bm{v}_{i,i}, \bm{v}_{i,j}, \bm{v}_{j,i}, \bm{v}_{j,j}\}
    \end{array}
    \right].\label{eq:IMP}
  \end{align}
  
  Conversely, let $\tilde{\bm{v}}$ be an eigenvector of $Q$ satisfying \eqref{eq:vTilSym} and \eqref{eq:vTilRank1}, i.e.,
  \begin{align*}
    \tilde{\bm{v}}=\alpha_i^2\bm{v}_{i,i}+\alpha_i\alpha_j\bm{v}_{i,j}+\alpha_j\alpha_i\bm{v}_{j,i}+\alpha_j^2\bm{v}_{j,j}
  \end{align*}
  with $\alpha_i,\alpha_j\in\mathbb{R}\backslash\{0\}$. From Theorem \ref{theo: JDviaED}, $\bm{v}_{i,i}, \bm{v}_{j,j}, \bm{v}_{i,j}$, and $\bm{v}_{j,i}$ are eigenvectors of $Q$ associated with $\lambda_{i,i}, \lambda_{i,j}, \lambda_{j,i}$ and $\lambda_{j,j}$ respectively. By using Lemma \ref{lem:eigVecLinInd}, these eigenvectors are linearly independent. Therefore the converse of in \eqref{eq:IMP} is true.

  (\ref{enum:vTilCond1}$\Leftrightarrow$\ref{enum:vTilCond2}) Since it is clear that the necessity of \ref{enum:vTilCond1} is guaranteed, we will establish its sufficiency. Let $\tilde{\bm{v}}'\in\mathbb{R}^{N^2}$ be any eigenvector of $Q$ such that
  \begin{align*}
    \tilde{\bm{v}}'\in\left\{\tilde{\bm{v}}\in\mathbb{R}^{N^2}\middle|
        \begin{array}{l}
          {\rm vec}^{-1}(\tilde{\bm{v}}) \text{ is symmetric,}\\
          {\rm rank}({\rm vec}^{-1}(\tilde{\bm{v}})) = 1
        \end{array}
    \right\}.
  \end{align*}
  Under the condition \ref{enum:vTilCond1},
  \begin{align*}
    \tilde{\bm{v}}'\in\bigcup_{i=1}^N\operatorname{span}\{\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)\}.
  \end{align*}

  Conversely, Let $\tilde{\bm{v}}''\in\mathbb{R}^{N^2}$ be any vector such that
  \begin{align*}
    \tilde{\bm{v}}''\in\bigcup_{i=1}^N\operatorname{span}\{\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)\}.
  \end{align*}
  Since, from Theorem \ref{theo: JDviaED}, $\operatorname{vec}(\bm{m}_i\bm{m}_i^\top)\ (i=1,2,\ldots ,N)$ are the eigenvectors of $Q$, $\tilde{\bm{v}}''$ is the eigenvector of $Q$. In addition, $\operatorname{rank}(\operatorname{vec}^{-1}(\tilde{\bm{v}}''))=1$ and $\operatorname{vec}^{-1}(\tilde{\bm{v}}'')$ is symmetric. Therefore,
  \begin{align*}
    \tilde{\bm{v}}''\in\left\{\tilde{\bm{v}}\in\mathbb{R}^{N^2}\middle|
        \begin{array}{l}
          {\rm vec}^{-1}(\tilde{\bm{v}}) \text{ is symmetric,}\\
          {\rm rank}({\rm vec}^{-1}(\tilde{\bm{v}})) = 1
        \end{array}
    \right\}.
  \end{align*}
\end{proof}


% \subsection{Sufficient Condition for Algorithm \ref{algo: proposed} to Solve Problem \ref{prob:SD}}
% In an extremely pessimistic view, Algorithm 1 does not necessarily find a solution of Problem \ref{prob:SD}. 
% In fact, eigenvectors $\{\hat{\bm{v}}_\iota\}_{\iota=1}^{N^2}$ obtained in Step 1 of Algorithm \ref{algo: proposed} may not include desired eigenvectors $\{\bm{v}_{i,i}\}_{i=1}^N$. 
% For example, if the two eigenvalues $\lambda_{1,1},\lambda_{2,2}$ in \eqref{eq: eigenpair} of $Q$ coincides, i.e., $\lambda_{1,1}=\lambda_{2,2}$, 
% \begin{align}
%   (\forall (\alpha_1,\alpha_2) \in \mathbb{R}^2\setminus \{(0,0)\}) \quad \alpha_1\bm{v}_{1,1}+\alpha_2\bm{v}_{2,2}
% \end{align}
% is also an eigenvector of $Q$. 
% Hence there is a possibility that $\hat{\bm{v}}_1=\bm{v}_{1,1}+\bm{v}_{2,2}$ and $\hat{\bm{v}}_2=\bm{v}_{1,1}-\bm{v}_{2,2}$ hold. 
% (note: the two matrices $\operatorname{vec}^{-1}(\bm{v}_{1,1}+\bm{v}_{2,2})$ and $\operatorname{vec}^{-1}(\bm{v}_{1,1}-\bm{v}_{2,2})$ are of rank $2$). In such a rare situation, Algorithm 1 does not necessarily find a solution of Problem \ref{prob:SD} because of failure in finding $N$ special eigenvectors of $Q$ in Step 2 of Algorithm \ref{algo: proposed}.
% 
% Paradoxically, if each of desired eigenvectors $\{\bm{v}_{i,i}\}_{i=1}^N$ corresponds to a simple eigenvalue, the above rare situation can be avoided. Since $\lambda_{i,j}=\lambda_{j,i}$ from \ref{enum:eigValEq} implies that eigenvectors $\bm{v}_{i,j}$ ($i,j=1,2,\ldots ,N\colon i \not = j$) must correspond to non-simple eigenvalues, the equivalence
% \begin{align*}
%   & (\text{$Q$ has $N$ simple eigenvalues})  \\
%   \Leftrightarrow & \ (\text{each of $\{\bm{v}_{i,i}\}_{i=1}^N$ corresponds to a simple eigenvalue})
% \end{align*}
% holds. Consequently, we establish the following theorem.
% We emphasize that the condition that $Q$ has $N$ simple eigenvalues holds almost always.
\section{Proposed algorithm}
\label{sec:proposedAlg}
In the case where $Q$ defined as in \eqref{eq:Q} has $N$ simple eigenvalues, the idea attained by Theorem \ref{theo:simpEigVal} yields our algorithm comprising following procedures: (i)obtain both the all eigenvalues and the all eigenvectors of $Q$; (ii)search the $N$ eigenvectors $\{\tilde{\bm{v}}_\iota\}^N_{\iota=1}$ associated with the $N$ simple eigenvalues; (iii)recover all column vectors of a solution $M$ of Problem \ref{prob:SD} from the first column vectors of $\operatorname{vec}^{-1}(\tilde{\bm{v}}_\iota)\ (\iota=1,2,\ldots ,N)$.

On the other hand, in the case where $Q$ does not have $N$ simple eigenvalues, we change the eigenvalues of $Q$ by using like DODO approach. The eigenvalue $\lambda_{i,j}\ (i,j=1,2,\ldots ,N)$ defined as in \eqref{eq: eigenpair} may change according to reduce matrices contained in $Q$, i.e., the quantities $\sum^T_{\tau=1}\sigma^{(\tau)}_i\sigma^{(\tau)}_j$ and
\begin{align*}
  (\exists \tau'\in\{1,2,\ldots ,T\})\ \sum^T_{\substack{\tau=1\\\tau\neq\tau'}}\sigma^{(\tau)}_i\sigma^{(\tau)}_j
\end{align*}
may be difference. (a)choose $R_{\tau'}$ from $\{R_\tau\}_{\tau=1}^T$ which is not diagonal; (b)diagonalize $R_{\tau'}$ with grouping together its repeated eigenvalues; (c)perform the same similarly transformation to the other matrices in $\{R_\tau\}_{\tau=1}^T$; (d)construct $Q'$ from each the $n$-by-$n\ (n>1)$ block matrices of $\{R_\tau\}_{\tau=1}^T\backslash\{R_{\tau'}\}$; (e)if $Q'$ has the $n$ simple eigenvalues, then apply previous procedures (ii) and (iii) to it, otherwise apply this procedures (a)-(e) to the blocks (see Algorithm \ref{algo: proposed} for its detail).

\begin{algorithm}[t]
  \SetAlgoLined
  \SetKwProg{Fn}{Function}{}{end}
  \SetKwFunction{Prop}{PropAlg}

  \KwIn{A simultaneous diagonalizable family $\{R_\tau\}_{\tau=1}^T\subset\mathbb{R}^{N\times N}$ in Problem \ref{prob:SD}}
  \KwOut{The diagonal family $\{\Sigma_\tau\}_{\tau=1}^T\subset\mathbb{R}^{N\times N}$ and a solution $M\in GL(N,\mathbb{R})$ of Problem \ref{prob:SD}}
  \BlankLine
  \Fn{\Prop{$\{B_\tau\}_{\tau=1}^T$}}{
    Let $n$ be the size of the matrices in $\{B_\tau\}_{\tau=1}^T$\;
    Let $\hat{B}_{k} \in \mathbb{R}^{T \times n}(k = 1, 2, \ldots , n)$ be matrices
    \begin{align*}
      \hat{B}_{k} & :=\left[
        \begin{array}{cccc}
          b^{(1)}_{k,1} & b^{(1)}_{k,2} & \cdots & b^{(1)}_{k,n}\\
          b^{(2)}_{k,1} & b^{(2)}_{k,2} & \cdots & b^{(2)}_{k,n}\\
                        & \vdots & & \\
          b^{(\tau)}_{k,1} & b^{(\tau)}_{k,2} & \cdots & b^{(\tau)}_{k,n}\\
                           & \vdots & & \\
          b^{(T)}_{k,1} & b^{(T)}_{k,2} & \cdots & b^{(T)}_{k,n}
        \end{array}
      \right]
    \end{align*}
    with $(k,l)$ entries $b^{(\tau)}_{k,l}\ (l=1,2,\ldots ,n)$ of $B_\tau\in\{B_{\tau}\}_{\tau=1}^{T}$\;
    Construct
    \begin{align*}
      Q=\left[
        \begin{array}{c}
          {\rm vec}(\hat{B}_{1}^\top\hat{B}_{1})^\top\\
          {\rm vec}(\hat{B}_{2}^\top\hat{B}_{1})^\top\\
          \vdots\\
          {\rm vec}(\hat{B}_{n}^\top\hat{B}_{1})^\top\\
          {\rm vec}(\hat{B}_{1}^\top\hat{B}_{2})^\top\\
          {\rm vec}(\hat{B}_{2}^\top\hat{B}_{2})^\top\\
          \vdots\\
          {\rm vec}(\hat{B}_{n}^\top\hat{B}_{n})^\top
        \end{array}
      \right]\in\mathbb{B}^{n^2\times n^2}
    \end{align*}
    \;
    \eIf{$Q$ has $n$ simple eigenvalues}{
      Let $\tilde{\bm{v}}_\iota\ (\iota=1,2,\ldots ,n)$ be the eigenvector of $Q$ associated with the $n$ simple eigenvalues\;
      Construct $\tilde{M}\in GL(n,\mathbb{R})$ by using the first column vectors of $\operatorname{vec}^{-1}(\tilde{\bm{v}}_\iota)\ (\iota=1,2,\ldots ,n)$\;
      Diagonalize all matrices in $\{B_\tau\}_{\tau=1}^T$ by performing the similarly transformation by the similarly matrix $\tilde{M}$\;
      \KwRet $\left(\{\tilde{M}^{-1}B_\tau\tilde{M}\}_{\tau=1}^T, \tilde{M}\right)$\;
      }{

    }
  }
  \caption{Proposed algorithm for Problem \ref{prob:SD}}
  \label{algo: proposed}
\end{algorithm}

\section{Conclusion}
\label{sec:conclision}
We have discovered a way to construct, from the solution of the high dimensional eigenvalue problem of $Q \in \mathbb{R}^{N^2 \times N^2}$, a solution of the JEVD problem, which can be used as a key strategy for general JEVD problem. Based on this discovery, we proposed non-iterative algorithms which produce a reliable estimate of diagonalizers compared with existing iterative algorithms. As a future work, we will investigate reliabilities of the proposed algorithms by numerical experiments and apply to the JVED applications e.g. blind source separation.


\bibliographystyle{ieicetr}% bib style
\bibliography{refs}% your bib database

%\profile{}{}
%\profile*{}{}% without picture of author's face

\end{document}
